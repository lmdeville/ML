{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection example for ENGR400\n",
    "# Prepared by Dr. Raju Gottumukkala\n",
    "\n",
    "import pandas as pd # Python module to work with tabular data\n",
    "import numpy as np # Python module which supports MATLAB like matrix operation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge # Linear Regression, Stocastic Gradient Decent\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error # Python modules to calculate different error metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from matplotlib import pyplot as plt # Python plotting functions\n",
    "import seaborn as sns # Special purpose plotting function\n",
    "import yfinance as yf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are subfunctions to calculate rolling average of mean and standard deviation for  window length 'w'\n",
    "#df is the data frame, col is the feature, and w is the window length\n",
    "def rollm(df, w, col):\n",
    "    return df[col].rolling(w).mean().shift(1)\n",
    "\n",
    "def rolls(df, w, col):\n",
    "    return df[col].rolling(w).std().shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelf (X_train, X_test, y_train, y_test):\n",
    "\n",
    "    svr = SVR(kernel = 'sigmoid', C=0.1, gamma=0.1)\n",
    "    svr.fit(X_train, y_train)\n",
    "    ysvr_pred= svr.predict(X_test)                            #\n",
    "\n",
    "    rfr = RandomForestRegressor()\n",
    "    rfr.fit(X_train, y_train)\n",
    "    yrfr_pred= rfr.predict(X_test)                           #\n",
    "\n",
    "    regr = LinearRegression() \n",
    "    regr.fit(X_train, y_train)\n",
    "    yLR_pred= regr.predict(X_test)\n",
    "    R_LR = np.corrcoef(y_test, yLR_pred)\n",
    "    \n",
    "    \n",
    "    # Calculate performance scores\n",
    "    MAE_svr=mean_absolute_error(y_test,ysvr_pred)\n",
    "    MSE_svr=mean_squared_error(y_test,ysvr_pred)\n",
    "    MAPE_svr=mean_absolute_percentage_error(y_test,ysvr_pred)\n",
    "\n",
    "\n",
    "    MAE_rfr=mean_absolute_error(y_test,yrfr_pred)\n",
    "    MSE_rfr=mean_squared_error(y_test,yrfr_pred)\n",
    "    MAPE_rfr=mean_absolute_percentage_error(y_test,yrfr_pred)\n",
    "\n",
    "    MAE_LR=mean_absolute_error(y_test, yLR_pred)\n",
    "    MSE_LR=mean_squared_error(y_test, yLR_pred)\n",
    "    MAPE_LR=mean_absolute_percentage_error(y_test, yLR_pred)\n",
    "    \n",
    "        \n",
    "    return np.array([[MAE_svr ,MAE_rfr ,MAE_LR],[MSE_svr ,MSE_rfr ,MSE_LR],[MAPE_svr ,MAPE_rfr ,MAPE_LR]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-06-01</th>\n",
       "      <td>46.21875</td>\n",
       "      <td>46.21875</td>\n",
       "      <td>44.71875</td>\n",
       "      <td>45.50000</td>\n",
       "      <td>20.054611</td>\n",
       "      <td>2455200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-06-02</th>\n",
       "      <td>45.00000</td>\n",
       "      <td>45.28125</td>\n",
       "      <td>44.40625</td>\n",
       "      <td>45.28125</td>\n",
       "      <td>19.958187</td>\n",
       "      <td>4548400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-06-05</th>\n",
       "      <td>45.37500</td>\n",
       "      <td>45.62500</td>\n",
       "      <td>45.12500</td>\n",
       "      <td>45.21875</td>\n",
       "      <td>19.930641</td>\n",
       "      <td>2703200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-06-06</th>\n",
       "      <td>45.25000</td>\n",
       "      <td>46.59375</td>\n",
       "      <td>45.21875</td>\n",
       "      <td>46.43750</td>\n",
       "      <td>20.467833</td>\n",
       "      <td>2582000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-06-07</th>\n",
       "      <td>46.93750</td>\n",
       "      <td>46.96875</td>\n",
       "      <td>45.84375</td>\n",
       "      <td>46.18750</td>\n",
       "      <td>20.357634</td>\n",
       "      <td>3026200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Open      High       Low     Close  Adj Close   Volume\n",
       "Date                                                                  \n",
       "2000-06-01  46.21875  46.21875  44.71875  45.50000  20.054611  2455200\n",
       "2000-06-02  45.00000  45.28125  44.40625  45.28125  19.958187  4548400\n",
       "2000-06-05  45.37500  45.62500  45.12500  45.21875  19.930641  2703200\n",
       "2000-06-06  45.25000  46.59375  45.21875  46.43750  20.467833  2582000\n",
       "2000-06-07  46.93750  46.96875  45.84375  46.18750  20.357634  3026200"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#STEP 0a: Read data\n",
    "# Here we are reading data and asking python to index the column as a date\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\n",
    "\n",
    "# df = pd.read_csv('TSLA.csv',index_col=0,parse_dates=[\"Date\"])\n",
    "df = yf.download('CVX','2000-06-01','2022-09-29')\n",
    "#print(df.to_string())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33708"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step1: Data pre-processing\n",
    "data = df.dropna(axis=0)\n",
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows with null values= 4064\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>open_1</th>\n",
       "      <th>open+1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-06-01</th>\n",
       "      <td>46.219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-06-02</th>\n",
       "      <td>45.000</td>\n",
       "      <td>46.219</td>\n",
       "      <td>45.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-06-05</th>\n",
       "      <td>45.375</td>\n",
       "      <td>45.000</td>\n",
       "      <td>45.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-06-06</th>\n",
       "      <td>45.250</td>\n",
       "      <td>45.375</td>\n",
       "      <td>46.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-06-07</th>\n",
       "      <td>46.938</td>\n",
       "      <td>45.250</td>\n",
       "      <td>46.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-06-08</th>\n",
       "      <td>46.219</td>\n",
       "      <td>46.938</td>\n",
       "      <td>46.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-06-09</th>\n",
       "      <td>46.500</td>\n",
       "      <td>46.219</td>\n",
       "      <td>46.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-06-12</th>\n",
       "      <td>46.406</td>\n",
       "      <td>46.500</td>\n",
       "      <td>46.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-06-13</th>\n",
       "      <td>46.000</td>\n",
       "      <td>46.406</td>\n",
       "      <td>46.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-06-14</th>\n",
       "      <td>46.031</td>\n",
       "      <td>46.000</td>\n",
       "      <td>46.531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open  open_1  open+1\n",
       "Date                              \n",
       "2000-06-01  46.219     NaN  45.000\n",
       "2000-06-02  45.000  46.219  45.375\n",
       "2000-06-05  45.375  45.000  45.250\n",
       "2000-06-06  45.250  45.375  46.938\n",
       "2000-06-07  46.938  45.250  46.219\n",
       "2000-06-08  46.219  46.938  46.500\n",
       "2000-06-09  46.500  46.219  46.406\n",
       "2000-06-12  46.406  46.500  46.000\n",
       "2000-06-13  46.000  46.406  46.031\n",
       "2000-06-14  46.031  46.000  46.531"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 2a: Feature extraction/computation\n",
    "\n",
    "#data = generate_new_features(df)\n",
    " # We will store the new features in this dataframe\n",
    "\n",
    "df_new = pd.DataFrame()\n",
    "df_new['Open'] = df['Open']\n",
    "\n",
    "# Next day variables (note the shift operator)      #\n",
    "\n",
    "# df_new['open+1'] = df['Open'].shift(-1)             #\n",
    "df_new['close+1'] = df['Close'].shift(-1)           #\n",
    "df_new['high+1'] = df['High'].shift(-1)             #\n",
    "df_new['low+1'] = df['Low'].shift(-1)               #\n",
    "df_new['volume+1'] = df['Volume'].shift(-1)         #\n",
    "\n",
    "# Previous day variables (note the shift operator)\n",
    "\n",
    "df_new['open_1'] = df['Open'].shift(1)\n",
    "df_new['close_1'] = df['Close'].shift(1)\n",
    "df_new['high_1'] = df['High'].shift(1)\n",
    "df_new['low_1'] = df['Low'].shift(1)\n",
    "df_new['volume_1'] = df['Volume'].shift(1)\n",
    "\n",
    "# avergae price\n",
    "df_new['avg_price_5'] = rollm(df, 5, 'Open')\n",
    "df_new['avg_price_30'] = rollm(df, 21, 'Open') \n",
    "df_new['avg_price_365'] = rollm(df, 252, 'Open')\n",
    "df_new['ratio_avg_price_5_30'] = df_new['avg_price_5'] / df_new['avg_price_30']       ##\n",
    "df_new['ratio_avg_price_5_365'] = df_new['avg_price_5'] / df_new['avg_price_365']     ##\n",
    "df_new['ratio_avg_price_30_365'] = df_new['avg_price_30'] / df_new['avg_price_365']   ##\n",
    "\n",
    "# average volume                                                                      ##\n",
    "df_new['avg_volume_5'] = rollm(df, 5, 'Volume')\n",
    "df_new['avg_volume_30'] = rollm(df, 21, 'Volume')\n",
    "df_new['avg_volume_365'] = rollm(df, 252, 'Volume') \n",
    "df_new['ratio_avg_volume_5_30'] = df_new['avg_volume_5'] / df_new['avg_volume_30']\n",
    "df_new['ratio_avg_volume_5_365'] = df_new['avg_volume_5'] / df_new['avg_volume_365']\n",
    "df_new['ratio_avg_volume_30_365'] = df_new['avg_volume_30'] / df_new['avg_volume_365']\n",
    "\n",
    "\n",
    "# Valume Std. Dev. \n",
    "df_new['std_volume_5'] = rolls(df, 5, 'Volume')     #\n",
    "df_new['std_volume_30'] = rolls(df, 21, 'Volume')                                       ##\n",
    "df_new['std_volume_365'] = rolls(df, 252, 'Volume')                                     ##\n",
    "df_new['ratio_std_volume_5_30'] = df_new['std_volume_5'] / df_new['std_volume_30']      ##\n",
    "df_new['ratio_std_volume_5_365'] = df_new['std_volume_5'] / df_new['std_volume_365']    ##\n",
    "df_new['ratio_std_volume_30_365'] = df_new['std_volume_30'] / df_new['std_volume_365']  ##\n",
    "\n",
    "# standard deviation of prices                     ##\n",
    "df_new['std_price_5'] = rolls(df, 5, 'Close')\n",
    "df_new['std_price_30'] = rolls(df, 21, 'Close')\n",
    "df_new['std_price_365'] = rolls(df, 252, 'Close')\n",
    "df_new['ratio_std_price_5_30'] = df_new['std_price_5'] / df_new['std_price_30']\n",
    "df_new['ratio_std_price_5_365'] = df_new['std_price_5'] / df_new['std_price_365']\n",
    "df_new['ratio_std_price_30_365'] = df_new['std_price_30'] / df_new['std_price_365']\n",
    "\n",
    "# return                                           ##\n",
    "df_new['return_1'] = ((df['Close'] - df['Close'].shift(1)) / df['Close'].shift(1)).shift(1)\n",
    "df_new['return_5'] = ((df['Close'] - df['Close'].shift(5)) / df['Close'].shift(5)).shift(1)\n",
    "df_new['return_30'] = ((df['Close'] - df['Close'].shift(21)) / df['Close'].shift(21)).shift(1)\n",
    "df_new['return_365'] = ((df['Close'] - df['Close'].shift(252)) / df['Close'].shift(252)).shift(1)\n",
    "df_new['moving_avg_5'] = rollm(df_new, 5, 'return_5')\n",
    "df_new['moving_avg_30'] = rollm(df_new, 21, 'return_30') \n",
    "df_new['moving_avg_365'] = rollm(df_new, 252, 'return_365')\n",
    "\n",
    "\n",
    "\n",
    "# The target variable       #\n",
    "df_new['open+1'] = df['Open'].shift(-1)            #\n",
    "\n",
    "# Note that we will have some null values and nan, we have to clearn them\n",
    "\n",
    "#check how many nan values\n",
    "print(\"rows with null values=\",df_new.isnull().sum().sum())\n",
    "\n",
    "#drop all the naans and round data to 3 digits\n",
    "data = df_new.dropna(axis=0)\n",
    "data = df_new.round(decimals=3)\n",
    "\n",
    "# Print the open values to make sure we understand the shift operator and target variable\n",
    "data[['Open','open_1', 'open+1']].head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>close+1</th>\n",
       "      <th>high+1</th>\n",
       "      <th>low+1</th>\n",
       "      <th>volume+1</th>\n",
       "      <th>open_1</th>\n",
       "      <th>close_1</th>\n",
       "      <th>high_1</th>\n",
       "      <th>low_1</th>\n",
       "      <th>volume_1</th>\n",
       "      <th>...</th>\n",
       "      <th>ratio_std_price_5_365</th>\n",
       "      <th>ratio_std_price_30_365</th>\n",
       "      <th>return_1</th>\n",
       "      <th>return_5</th>\n",
       "      <th>return_30</th>\n",
       "      <th>return_365</th>\n",
       "      <th>moving_avg_5</th>\n",
       "      <th>moving_avg_30</th>\n",
       "      <th>moving_avg_365</th>\n",
       "      <th>open+1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5618.000000</td>\n",
       "      <td>5617.000000</td>\n",
       "      <td>5617.000000</td>\n",
       "      <td>5617.000000</td>\n",
       "      <td>5.617000e+03</td>\n",
       "      <td>5617.000000</td>\n",
       "      <td>5617.000000</td>\n",
       "      <td>5617.000000</td>\n",
       "      <td>5617.000000</td>\n",
       "      <td>5.617000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>5366.000000</td>\n",
       "      <td>5366.000000</td>\n",
       "      <td>5616.000000</td>\n",
       "      <td>5612.000000</td>\n",
       "      <td>5596.000000</td>\n",
       "      <td>5365.000000</td>\n",
       "      <td>5607.000000</td>\n",
       "      <td>5575.000000</td>\n",
       "      <td>5113.000000</td>\n",
       "      <td>5617.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>86.523671</td>\n",
       "      <td>86.537103</td>\n",
       "      <td>87.352382</td>\n",
       "      <td>85.675544</td>\n",
       "      <td>8.288285e+06</td>\n",
       "      <td>86.513780</td>\n",
       "      <td>86.519250</td>\n",
       "      <td>87.334540</td>\n",
       "      <td>85.658332</td>\n",
       "      <td>8.287248e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188193</td>\n",
       "      <td>0.365136</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.007185</td>\n",
       "      <td>0.079530</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>0.007439</td>\n",
       "      <td>0.069260</td>\n",
       "      <td>86.530847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>31.200147</td>\n",
       "      <td>31.209005</td>\n",
       "      <td>31.426711</td>\n",
       "      <td>30.962409</td>\n",
       "      <td>4.318687e+06</td>\n",
       "      <td>31.194115</td>\n",
       "      <td>31.203791</td>\n",
       "      <td>31.421608</td>\n",
       "      <td>30.958299</td>\n",
       "      <td>4.319388e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.129444</td>\n",
       "      <td>0.211419</td>\n",
       "      <td>0.017574</td>\n",
       "      <td>0.036315</td>\n",
       "      <td>0.070806</td>\n",
       "      <td>0.214758</td>\n",
       "      <td>0.029308</td>\n",
       "      <td>0.055138</td>\n",
       "      <td>0.165575</td>\n",
       "      <td>31.198289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>31.110001</td>\n",
       "      <td>30.924999</td>\n",
       "      <td>31.670000</td>\n",
       "      <td>30.655001</td>\n",
       "      <td>1.067000e+06</td>\n",
       "      <td>31.110001</td>\n",
       "      <td>30.924999</td>\n",
       "      <td>31.670000</td>\n",
       "      <td>30.655001</td>\n",
       "      <td>1.067000e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008554</td>\n",
       "      <td>0.069025</td>\n",
       "      <td>-0.221248</td>\n",
       "      <td>-0.336987</td>\n",
       "      <td>-0.502614</td>\n",
       "      <td>-0.560584</td>\n",
       "      <td>-0.252548</td>\n",
       "      <td>-0.309768</td>\n",
       "      <td>-0.284382</td>\n",
       "      <td>31.110001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>59.185000</td>\n",
       "      <td>59.250000</td>\n",
       "      <td>59.740002</td>\n",
       "      <td>58.500000</td>\n",
       "      <td>5.384000e+06</td>\n",
       "      <td>59.180000</td>\n",
       "      <td>59.240002</td>\n",
       "      <td>59.720001</td>\n",
       "      <td>58.490002</td>\n",
       "      <td>5.383700e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102304</td>\n",
       "      <td>0.216876</td>\n",
       "      <td>-0.008065</td>\n",
       "      <td>-0.016907</td>\n",
       "      <td>-0.031928</td>\n",
       "      <td>-0.049068</td>\n",
       "      <td>-0.013542</td>\n",
       "      <td>-0.023444</td>\n",
       "      <td>-0.046431</td>\n",
       "      <td>59.200001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>89.945000</td>\n",
       "      <td>89.919998</td>\n",
       "      <td>91.029999</td>\n",
       "      <td>88.809998</td>\n",
       "      <td>7.238400e+06</td>\n",
       "      <td>89.940002</td>\n",
       "      <td>89.910004</td>\n",
       "      <td>90.980003</td>\n",
       "      <td>88.800003</td>\n",
       "      <td>7.238300e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156549</td>\n",
       "      <td>0.317191</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.008255</td>\n",
       "      <td>0.078723</td>\n",
       "      <td>0.002650</td>\n",
       "      <td>0.007496</td>\n",
       "      <td>0.086164</td>\n",
       "      <td>89.949997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>111.529999</td>\n",
       "      <td>111.580002</td>\n",
       "      <td>112.349998</td>\n",
       "      <td>110.680000</td>\n",
       "      <td>1.004780e+07</td>\n",
       "      <td>111.529999</td>\n",
       "      <td>111.580002</td>\n",
       "      <td>112.339996</td>\n",
       "      <td>110.599998</td>\n",
       "      <td>1.004780e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234206</td>\n",
       "      <td>0.464857</td>\n",
       "      <td>0.008945</td>\n",
       "      <td>0.021584</td>\n",
       "      <td>0.047431</td>\n",
       "      <td>0.212182</td>\n",
       "      <td>0.018178</td>\n",
       "      <td>0.040034</td>\n",
       "      <td>0.182285</td>\n",
       "      <td>111.529999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>180.949997</td>\n",
       "      <td>181.130005</td>\n",
       "      <td>182.399994</td>\n",
       "      <td>180.250000</td>\n",
       "      <td>5.723100e+07</td>\n",
       "      <td>180.949997</td>\n",
       "      <td>181.130005</td>\n",
       "      <td>182.399994</td>\n",
       "      <td>180.250000</td>\n",
       "      <td>5.723100e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>1.671183</td>\n",
       "      <td>1.912089</td>\n",
       "      <td>0.227407</td>\n",
       "      <td>0.330894</td>\n",
       "      <td>0.583470</td>\n",
       "      <td>0.891372</td>\n",
       "      <td>0.232624</td>\n",
       "      <td>0.250792</td>\n",
       "      <td>0.494462</td>\n",
       "      <td>180.949997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open      close+1       high+1        low+1      volume+1  \\\n",
       "count  5618.000000  5617.000000  5617.000000  5617.000000  5.617000e+03   \n",
       "mean     86.523671    86.537103    87.352382    85.675544  8.288285e+06   \n",
       "std      31.200147    31.209005    31.426711    30.962409  4.318687e+06   \n",
       "min      31.110001    30.924999    31.670000    30.655001  1.067000e+06   \n",
       "25%      59.185000    59.250000    59.740002    58.500000  5.384000e+06   \n",
       "50%      89.945000    89.919998    91.029999    88.809998  7.238400e+06   \n",
       "75%     111.529999   111.580002   112.349998   110.680000  1.004780e+07   \n",
       "max     180.949997   181.130005   182.399994   180.250000  5.723100e+07   \n",
       "\n",
       "            open_1      close_1       high_1        low_1      volume_1  ...  \\\n",
       "count  5617.000000  5617.000000  5617.000000  5617.000000  5.617000e+03  ...   \n",
       "mean     86.513780    86.519250    87.334540    85.658332  8.287248e+06  ...   \n",
       "std      31.194115    31.203791    31.421608    30.958299  4.319388e+06  ...   \n",
       "min      31.110001    30.924999    31.670000    30.655001  1.067000e+06  ...   \n",
       "25%      59.180000    59.240002    59.720001    58.490002  5.383700e+06  ...   \n",
       "50%      89.940002    89.910004    90.980003    88.800003  7.238300e+06  ...   \n",
       "75%     111.529999   111.580002   112.339996   110.599998  1.004780e+07  ...   \n",
       "max     180.949997   181.130005   182.399994   180.250000  5.723100e+07  ...   \n",
       "\n",
       "       ratio_std_price_5_365  ratio_std_price_30_365     return_1  \\\n",
       "count            5366.000000             5366.000000  5616.000000   \n",
       "mean                0.188193                0.365136     0.000356   \n",
       "std                 0.129444                0.211419     0.017574   \n",
       "min                 0.008554                0.069025    -0.221248   \n",
       "25%                 0.102304                0.216876    -0.008065   \n",
       "50%                 0.156549                0.317191     0.000693   \n",
       "75%                 0.234206                0.464857     0.008945   \n",
       "max                 1.671183                1.912089     0.227407   \n",
       "\n",
       "          return_5    return_30   return_365  moving_avg_5  moving_avg_30  \\\n",
       "count  5612.000000  5596.000000  5365.000000   5607.000000    5575.000000   \n",
       "mean      0.001708     0.007185     0.079530      0.001748       0.007439   \n",
       "std       0.036315     0.070806     0.214758      0.029308       0.055138   \n",
       "min      -0.336987    -0.502614    -0.560584     -0.252548      -0.309768   \n",
       "25%      -0.016907    -0.031928    -0.049068     -0.013542      -0.023444   \n",
       "50%       0.002717     0.008255     0.078723      0.002650       0.007496   \n",
       "75%       0.021584     0.047431     0.212182      0.018178       0.040034   \n",
       "max       0.330894     0.583470     0.891372      0.232624       0.250792   \n",
       "\n",
       "       moving_avg_365       open+1  \n",
       "count     5113.000000  5617.000000  \n",
       "mean         0.069260    86.530847  \n",
       "std          0.165575    31.198289  \n",
       "min         -0.284382    31.110001  \n",
       "25%         -0.046431    59.200001  \n",
       "50%          0.086164    89.949997  \n",
       "75%          0.182285   111.529999  \n",
       "max          0.494462   180.949997  \n",
       "\n",
       "[8 rows x 42 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 2a: Feature extraction/computation\n",
    "\n",
    "# Understand the range of values for each feature\n",
    "df_new.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5618\n"
     ]
    }
   ],
   "source": [
    "# step 2b: Feature standardization / normalization\n",
    "\n",
    "# store all the data in the feature table data frame named 'ft'\n",
    "ft = data[['avg_price_5','std_volume_5','avg_price_30','close_1','volume_1','avg_price_365','ratio_avg_price_5_30','ratio_avg_price_5_365','ratio_avg_price_30_365'\n",
    "           ,'avg_volume_5','avg_volume_30','avg_volume_365','ratio_avg_volume_5_30','ratio_avg_volume_5_365','ratio_avg_volume_30_365','std_volume_30','std_volume_365'\n",
    "           ,'ratio_std_volume_5_30','ratio_std_volume_5_365','ratio_std_volume_30_365','std_price_5','std_price_30','std_price_365','ratio_std_price_5_30'\n",
    "           ,'ratio_std_price_5_365','ratio_std_price_30_365','return_1','return_5','return_30','return_365','moving_avg_5','moving_avg_30','moving_avg_365'\n",
    "           ,'close+1','high+1','low+1','volume+1','open_1','high_1','low_1','Open','open+1']]\n",
    "\n",
    "len_idx = len(data.index)\n",
    "print(len_idx)\n",
    "\n",
    "#drop all the naans and round data to 3 digits\n",
    "ft = ft.dropna(axis=0)\n",
    "ft = ft.round(decimals=3)\n",
    "\n",
    "#seperate the data into training and testing sets\n",
    "ft2_X =ft.drop(['open+1', 'close+1', 'low+1', 'high+1'], axis=1)\n",
    "ft2_Y =ft['open+1']\n",
    "\n",
    "#x = ft.values #returns a numpy \n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# standard_scaler =  preprocessing.StandardScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(ft2_X)\n",
    "#x_scaled = standard_scaler.fit_transform(ft)\n",
    "\n",
    "ft2 = pd.DataFrame(x_scaled,columns=ft2_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3: Fit the model with all the features (Without any selection)\n",
    "\n",
    "X_train, X_test, y_train, y_test =train_test_split(ft2_X,ft2_Y,test_size=0.3, shuffle=0.1)\n",
    "all_array = modelf (X_train, X_test, y_train, y_test)\n",
    "all_feat = pd.DataFrame(my_array,index=['mean_absolute_error' ,'mean_squared_error' ,'mean_absolute_percentage_error'],columns=['SVR' ,'RFR' ,'LR'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECTED FEATURES= Index(['avg_price_365', 'avg_volume_365', 'std_volume_365'], dtype='object')\n",
      "\n",
      "PERFORMANCE WITH ALL FEATURES\n",
      "\n",
      "                                         SVR           RFR            LR\n",
      "mean_absolute_error             5.762633e-02  8.328509e-03  4.864857e-02\n",
      "mean_squared_error              6.057956e-03  2.641730e-04  4.928911e-03\n",
      "mean_absolute_percentage_error  3.297115e+11  1.666113e+10  1.499604e+11\n",
      " \n",
      "PERFORMANCE WITH  3 FEATURES\n",
      "                                     SVR       RFR        LR\n",
      "mean_absolute_error             0.060104  0.008435  0.051671\n",
      "mean_squared_error              0.006641  0.000196  0.005409\n",
      "mean_absolute_percentage_error  0.515685  0.030425  0.273743\n"
     ]
    }
   ],
   "source": [
    "# step 2c: Feature selection with variance threshold\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "selector = VarianceThreshold(threshold=.05)\n",
    "selector.fit(X)\n",
    "X_V=X.columns[selector.get_support()]\n",
    "\n",
    "print(\"SELECTED FEATURES=\",X_V)\n",
    "\n",
    "#print(X[X_V].info())\n",
    "X_train, X_test, y_train, y_test =train_test_split(X[X_V],Y,test_size=0.3, shuffle=0.1)\n",
    "my_array2 = modelf (X_train, X_test, y_train, y_test)\n",
    "sel_feat = pd.DataFrame(my_array2,index=['mean_absolute_error' ,'mean_squared_error' ,'mean_absolute_percentage_error'],columns=['SVR' ,'RFR' ,'LR'])\n",
    "\n",
    "print(\"\\nPERFORMANCE WITH ALL FEATURES\\n\")\n",
    "print(all_feat)\n",
    "print(\" \\nPERFORMANCE WITH \", len(X_V),\"FEATURES\")\n",
    "print(sel_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open              3.017080\n",
      "close_1           2.891619\n",
      "high_1            2.818157\n",
      "low_1             2.789252\n",
      "open_1            2.696200\n",
      "avg_price_5       2.509278\n",
      "avg_price_30      2.164278\n",
      "avg_price_365     1.955140\n",
      "std_volume_365    1.677398\n",
      "avg_volume_365    1.602198\n",
      "dtype: float64\n",
      "\n",
      "PERFORMANCE WITH ALL FEATURES\n",
      "\n",
      "                                         SVR           RFR            LR\n",
      "mean_absolute_error             5.762633e-02  8.328509e-03  4.864857e-02\n",
      "mean_squared_error              6.057956e-03  2.641730e-04  4.928911e-03\n",
      "mean_absolute_percentage_error  3.297115e+11  1.666113e+10  1.499604e+11\n",
      " \n",
      "PERFORMANCE WITH  10 FEATURES\n",
      "                                     SVR       RFR        LR\n",
      "mean_absolute_error             0.038399  0.007368  0.006923\n",
      "mean_squared_error              0.002032  0.000122  0.000106\n",
      "mean_absolute_percentage_error  0.135620  0.073381  0.098543\n"
     ]
    }
   ],
   "source": [
    "# step 2c: Feature selection with mutual info\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "# #Select top k features based on mutual info regression\n",
    "\n",
    "mutual_info = mutual_info_regression(X,Y)\n",
    "selector = SelectKBest(mutual_info_regression, k =2)\n",
    "selector.fit(X, Y)\n",
    "X.columns[selector.get_support()]\n",
    "\n",
    "mutual_info=pd.Series(mutual_info)\n",
    "mutual_info.index = X.columns\n",
    "T = mutual_info.sort_values(ascending=False)\n",
    "\n",
    "# change k to change the features\n",
    "k=10\n",
    "print(T[:k])\n",
    "#X[T[:].index]\n",
    "F = X[T[:k].index]\n",
    "X_train, X_test, y_train, y_test =train_test_split(F,Y,test_size=0.3, shuffle=0.1)\n",
    "my_array2 = modelf (X_train, X_test, y_train, y_test)\n",
    "sel_feat = pd.DataFrame(my_array2,index=['mean_absolute_error' ,'mean_squared_error' ,'mean_absolute_percentage_error'],columns=['SVR' ,'RFR' ,'LR'])\n",
    "\n",
    "print(\"\\nPERFORMANCE WITH ALL FEATURES\\n\")\n",
    "print(all_feat)\n",
    "print(\" \\nPERFORMANCE WITH \", k,\"FEATURES\")\n",
    "print(sel_feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['std_price_30', 'return_5', 'moving_avg_5', 'moving_avg_30', 'Open']\n",
      "\n",
      "PERFORMANCE WITH ALL FEATURES\n",
      "\n",
      "                                         SVR           RFR            LR\n",
      "mean_absolute_error             5.762633e-02  8.328509e-03  4.864857e-02\n",
      "mean_squared_error              6.057956e-03  2.641730e-04  4.928911e-03\n",
      "mean_absolute_percentage_error  3.297115e+11  1.666113e+10  1.499604e+11\n",
      " \n",
      "PERFORMANCE WITH  5 FEATURES\n",
      "                                     SVR       RFR        LR\n",
      "mean_absolute_error             0.049878  0.007682  0.007067\n",
      "mean_squared_error              0.003446  0.000115  0.000099\n",
      "mean_absolute_percentage_error  0.596324  0.032035  0.030616\n"
     ]
    }
   ],
   "source": [
    "# step 2c: Feature selection with sequential feature selector\n",
    "\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "K=5\n",
    "\n",
    "# Instantiate the estimator and the model\n",
    "regr = LinearRegression() \n",
    "sfs = SequentialFeatureSelector(regr,n_features_to_select=K)\n",
    "\n",
    "# Fit the data to determine the k_features which give the\n",
    "# most optimal model performance\n",
    "sfs.fit(X,Y)\n",
    "\n",
    "\n",
    "#print(sfs.get_support())\n",
    "# Transform the training data set to dataset having k_features\n",
    "# giving most optimal model performance\n",
    "\n",
    "print(list(X.columns[sfs.get_support()]))\n",
    "\n",
    "F=X[X.columns[sfs.get_support()]]\n",
    "\n",
    "X_train, X_test, y_train, y_test =train_test_split(F,Y,test_size=0.3, shuffle=0.1)\n",
    "\n",
    "my_array2 = modelf (X_train, X_test, y_train, y_test)\n",
    "sel_feat = pd.DataFrame(my_array2,index=['mean_absolute_error' ,'mean_squared_error' ,'mean_absolute_percentage_error'],columns=['SVR' ,'RFR' ,'LR'])\n",
    "\n",
    "print(\"\\nPERFORMANCE WITH ALL FEATURES\\n\")\n",
    "print(all_feat)\n",
    "print(\" \\nPERFORMANCE WITH \", K,\"FEATURES\")\n",
    "print(sel_feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      std_price_30  return_5  moving_avg_5  moving_avg_30      Open\n",
      "0         0.018588  0.504491      0.483539       0.582888  0.083022\n",
      "1         0.020515  0.501497      0.495885       0.579323  0.082355\n",
      "2         0.022069  0.497006      0.506173       0.575758  0.081854\n",
      "3         0.019707  0.497006      0.510288       0.573975  0.081854\n",
      "4         0.016971  0.520958      0.512346       0.563280  0.081854\n",
      "...            ...       ...           ...            ...       ...\n",
      "5107      0.181649  0.474551      0.537037       0.614973  0.848905\n",
      "5108      0.188052  0.428144      0.522634       0.606061  0.844167\n",
      "5109      0.193584  0.450599      0.481481       0.598930  0.791778\n",
      "5110      0.261780  0.392216      0.454733       0.586453  0.750534\n",
      "5111      0.332774  0.351796      0.432099       0.568627  0.741991\n",
      "\n",
      "[5112 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X[X.columns[sfs.get_support()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['avg_price_5', 'close_1', 'volume_1', 'ratio_avg_price_5_30', 'ratio_avg_price_5_365', 'ratio_avg_price_30_365', 'volume+1', 'high_1', 'low_1', 'Open']\n",
      "\n",
      "PERFORMANCE WITH ALL FEATURES\n",
      "\n",
      "                                         SVR           RFR            LR\n",
      "mean_absolute_error             5.762633e-02  8.328509e-03  4.864857e-02\n",
      "mean_squared_error              6.057956e-03  2.641730e-04  4.928911e-03\n",
      "mean_absolute_percentage_error  3.297115e+11  1.666113e+10  1.499604e+11\n",
      " \n",
      "PERFORMANCE WITH  10 FEATURES\n",
      "                                     SVR       RFR        LR\n",
      "mean_absolute_error             0.052428  0.007474  0.006889\n",
      "mean_squared_error              0.003761  0.000123  0.000107\n",
      "mean_absolute_percentage_error  1.322868  0.088724  0.096918\n"
     ]
    }
   ],
   "source": [
    "# step 2c: Feature selection with RFE based feature selector\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "K=10\n",
    "regr = LinearRegression() \n",
    "rfe = RFE(regr, n_features_to_select=K)\n",
    "rfe.fit(X,Y)\n",
    "\n",
    "#print(rfe.get_support())\n",
    "# Transform the training data set to dataset having k_features\n",
    "# giving most optimal model performance\n",
    "\n",
    "print(list(X.columns[rfe.get_support()]))\n",
    "\n",
    "F=X[X.columns[sfs.get_support()]]\n",
    "\n",
    "X_train, X_test, y_train, y_test =train_test_split(F,Y,test_size=0.3, shuffle=0.1)\n",
    "\n",
    "my_array2 = modelf (X_train, X_test, y_train, y_test)\n",
    "sel_feat = pd.DataFrame(my_array2,index=['mean_absolute_error' ,'mean_squared_error' ,'mean_absolute_percentage_error'],columns=['SVR' ,'RFR' ,'LR'])\n",
    "\n",
    "print(\"\\nPERFORMANCE WITH ALL FEATURES\\n\")\n",
    "print(all_feat)\n",
    "print(\" \\nPERFORMANCE WITH \", K,\"FEATURES\")\n",
    "print(sel_feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PERFORMANCE WITH ALL FEATURES\n",
      "\n",
      "                                         SVR           RFR            LR\n",
      "mean_absolute_error             5.762633e-02  8.328509e-03  4.864857e-02\n",
      "mean_squared_error              6.057956e-03  2.641730e-04  4.928911e-03\n",
      "mean_absolute_percentage_error  3.297115e+11  1.666113e+10  1.499604e+11\n",
      " \n",
      "PERFORMANCE WITH  12 FEATURES\n",
      "                                         SVR           RFR            LR\n",
      "mean_absolute_error             4.137171e-02  7.475027e-03  6.808347e-03\n",
      "mean_squared_error              2.340014e-03  1.076066e-04  9.243188e-05\n",
      "mean_absolute_percentage_error  2.278100e+11  1.861262e+10  1.578077e+10\n"
     ]
    }
   ],
   "source": [
    "# step 2c: Feature selection with RF approach (using GINI index)\n",
    "\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X, Y)\n",
    "importances = rfr.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "k=12\n",
    "\n",
    "X1 = X.columns[sorted_idx]\n",
    "X2 = rfr.feature_importances_[sorted_idx]\n",
    "A = pd.DataFrame(columns=['X1','X2'])\n",
    "A.X1=X1\n",
    "A.X2=X2\n",
    "B=A.sort_values('X2', axis=0,ascending=False).reset_index()\n",
    "C=B.X1[0:K].values.tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test =train_test_split(X[C],Y,test_size=0.3, shuffle=0.1)\n",
    "\n",
    "my_array2 = modelf (X_train, X_test, y_train, y_test)\n",
    "sel_feat = pd.DataFrame(my_array2,index=['mean_absolute_error' ,'mean_squared_error' ,'mean_absolute_percentage_error'],columns=['SVR' ,'RFR' ,'LR'])\n",
    "\n",
    "print(\"\\nPERFORMANCE WITH ALL FEATURES\\n\")\n",
    "print(all_feat)\n",
    "print(\" \\nPERFORMANCE WITH \", k,\"FEATURES\")\n",
    "print(sel_feat)\n",
    "\n",
    "\n",
    "#plt.barh(X.columns, rfr.feature_importances_)\n",
    "\n",
    "# sorted_idx = rfr.feature_importances_.argsort()\n",
    "# plt.barh(X.columns[sorted_idx], rfr.feature_importances_[sorted_idx])\n",
    "# plt.xlabel(\"Random Forest Feature Importance\")\n",
    "\n",
    "# sorted_idx = rfr.feature_importances.argsort()\n",
    "# rfr.feature_importances_[sorted_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PERFORMANCE WITH ALL FEATURES\n",
      "\n",
      "                                         SVR           RFR            LR\n",
      "mean_absolute_error             5.762633e-02  8.328509e-03  4.864857e-02\n",
      "mean_squared_error              6.057956e-03  2.641730e-04  4.928911e-03\n",
      "mean_absolute_percentage_error  3.297115e+11  1.666113e+10  1.499604e+11\n",
      " \n",
      "PERFORMANCE WITH  5 FEATURES\n",
      "                                     SVR       RFR        LR\n",
      "mean_absolute_error             0.046543  0.009084  0.012051\n",
      "mean_squared_error              0.002863  0.000169  0.000273\n",
      "mean_absolute_percentage_error  0.956350  0.094490  0.065482\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# define transform\n",
    "pca = PCA(n_components=5)\n",
    "\n",
    "#pca = PCA(n_components = 5)\n",
    "# prepare transform on dataset\n",
    "pca.fit(X)\n",
    "# apply transform to dataset\n",
    "transformed = pca.transform(X)\n",
    "data_pca = pd.DataFrame(transformed,columns=['PC1','PC2','PC3','PC4','PC5'])\n",
    "data_pca.head()\n",
    "\n",
    "X_train, X_test, y_train, y_test =train_test_split(data_pca,Y,test_size=0.3, shuffle=0.1)\n",
    "\n",
    "my_array2 = modelf (X_train, X_test, y_train, y_test)\n",
    "sel_feat = pd.DataFrame(my_array2,index=['mean_absolute_error' ,'mean_squared_error' ,'mean_absolute_percentage_error'],columns=['SVR' ,'RFR' ,'LR'])\n",
    "\n",
    "print(\"\\nPERFORMANCE WITH ALL FEATURES\\n\")\n",
    "print(all_feat)\n",
    "print(\" \\nPERFORMANCE WITH \", '5',\"FEATURES\")\n",
    "print(sel_feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         SVR           RFR            LR\n",
      "mean_absolute_error             4.381486e-02  8.636371e-03  1.188400e-02\n",
      "mean_squared_error              2.779750e-03  1.682787e-04  3.074177e-04\n",
      "mean_absolute_percentage_error  2.020490e+11  4.170131e+10  4.682058e+10\n",
      "\n",
      "**after feature selection using variance threshold**\n",
      "\n",
      "                                     SVR       RFR        LR\n",
      "mean_absolute_error             0.040470  0.008344  0.011891\n",
      "mean_squared_error              0.002473  0.000158  0.000299\n",
      "mean_absolute_percentage_error  0.274373  0.032087  0.045612\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
